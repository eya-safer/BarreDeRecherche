# Architecture du Syst√®me üèóÔ∏è

Ce document d√©taille l'architecture technique du Mini Moteur de Recherche.

## üìä Diagramme d'Architecture

```mermaid
graph TD
    User((Utilisateur))
    
    subgraph Data_Layer [Couche Donn√©es]
        Docs[Documents JSON]
        Meta[Metadonn√©es CSV]
        Index[Index Invers√© JSON]
    end

    subgraph Collection_Module
        Crawler[data_collector.py]
        Wiki(Wikipedia API)
    end

    subgraph Processing_Module
        Indexer[indexer.py]
        Cleaner[preprocessing.py]
    end

    subgraph Search_Module
        Engine[search_engine.py]
        Ranker{Ranking BM25}
    end

    subgraph Interface_Module
        WebUI[app.py (Streamlit)]
        CLI[Interface CMD]
    end

    %% Flux
    Wiki --> Crawler
    Crawler --> Docs
    Crawler --> Meta
    
    Docs --> Cleaner
    Cleaner --> Indexer
    Indexer --> Index
    
    User --> WebUI
    WebUI --> Engine
    Engine --> Cleaner
    Engine --> Ranker
    Index --> Engine
    Ranker --> WebUI
```

## üß© Modules et Responsabilit√©s

### 1. Module de Collecte (`data_collector.py`)
*   **R√¥le** : Constituer le corpus.
*   **Technologie** : Librairie `wikipedia`.
*   **Fonctionnement** : It√®re sur une liste de sujets pr√©d√©finis, t√©l√©charge le contenu, le r√©sum√© et l'URL, et sauvegarde chaque article dans un fichier JSON individuel pour simuler des documents web distincts.

### 2. Module de Pr√©traitement (`preprocessing.py`)
*   **R√¥le** : Normaliser le texte pour r√©duire le vocabulaire et am√©liorer les correspondances.
*   **Techniques utilis√©es** :
    *   **Tokenization** : D√©coupage en mots (`nltk.word_tokenize`).
    *   **Lowercasing** : Mise en minuscules.
    *   **Stop word removal** : Suppression des mots vides (le, la, de...) via `nltk.corpus.stopwords`.
    *   **Stemming** : R√©duction aux racines (ex: "playing" -> "play") via `PorterStemmer`.

### 3. Module d'Indexation (`indexer.py`)
*   **R√¥le** : Cr√©er la structure de donn√©es permettant la recherche rapide.
*   **Structure** : Index Invers√© (`Terme -> {DocID: Fr√©quence}`).
*   **Optimisation** : Calcule et stocke √©galement la longueur de chaque document (`doc_lengths`) et la longueur moyenne (`avg_doc_length`) n√©cessaire pour l'algorithme BM25, √©vitant de le recalculer √† chaque requ√™te.

### 4. Module de Recherche (`search_engine.py`)
*   **R√¥le** : Traiter la requ√™te et classer les documents.
*   **Algorithme : Okapi BM25**.
    *   Formule utilis√©e :
        $$ Score(D,Q) = \sum_{i=1}^{n} IDF(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{avgdl})} $$
    *   Param√®tres choisis : $k_1 = 1.5$, $b = 0.75$ (Standards usuels).

### 5. Interface (`app.py`)
*   **R√¥le** : Interaction utilisateur.
*   **Technologie** : **Streamlit**. C'est un framework Python permettant de cr√©er des applications web de data science tr√®s rapidement sans √©crire de HTML/CSS/JS. Il g√®re l'affichage des r√©sultats, la saisie utilisateur et le slider pour le param√®tre K.

## üõ†Ô∏è Choix Techniques

*   **Langage** : **Python** pour sa richesse en biblioth√®ques de traitement de texte (NLTK) et sa simplicit√©.
*   **Stockage** : **Fichiers JSON**. Pour un corpus de <1000 documents, une base de donn√©es SQL/NoSQL ajouterait de la complexit√© inutile. JSON est lisible et natif en Python.
*   **Librairie de NLP** : **NLTK** (Natural Language Toolkit). Standard acad√©mique, robuste pour le stemming et les stop words.
*   **Architecture** : Modulaire. Chaque script peut √™tre ex√©cut√© ind√©pendamment, ce qui facilite le d√©bogage et l'√©valuation (comme demand√© dans les "Conseils" du projet).
